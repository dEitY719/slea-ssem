# REQ-CLI-Agent-4: agent batch-score Î™ÖÎ†π (Î≥ëÎ†¨ Î∞∞Ïπò Ï±ÑÏ†ê)

**Status**: Phase 1Ô∏è‚É£ - SPECIFICATION (Pending Review)
**Priority**: üü° MEDIUM
**Dependencies**: [REQ-CLI-Agent-1] ‚úÖ DONE, [REQ-A-Mode2-Tool6] ‚úÖ DONE
**Target Completion**: Phase 4 ‚úÖ Done

---

## üìã Phase 1: SPECIFICATION

### 1.1 Requirement Summary

Implement `agent batch-score` CLI command that:
- Scores multiple answers in parallel using Tool 6
- Processes answers concurrently for improved performance
- Supports batch JSON file input with array of questions
- Returns summary with individual scores and aggregate statistics

### 1.2 Feature Intent

Enable CLI users to score multiple answers efficiently using parallel execution, supporting:
- REQ-A-Mode2-Tool6: Parallel answer scoring with LLM-based explanation
- Batch processing from JSON files (array format)
- Concurrent execution via asyncio.gather()
- Performance improvement for bulk scoring operations
- Detailed summary with statistics

### 1.3 Detailed Specification

#### Location & Implementation

**Files to Create/Modify**:
- ‚úÖ Modify: `src/cli/actions/agent.py` (replace placeholder in `batch_score()`)
- ‚úÖ New: Comprehensive test suite in `tests/cli/test_agent_batch_score.py`

#### Command Signature

```bash
agent batch-score [OPTIONS]

Options:
  --batch-file TEXT       Path to JSON file with batch (required)
  --parallel INTEGER      Number of parallel workers (optional, default: 3)
  --output TEXT          Output file path for results (optional)
  --help                 Show help
```

#### Input JSON Format

```json
[
  {
    "question_id": "q_001",
    "question": "What is X?",
    "answer_type": "multiple_choice",
    "user_answer": "Option A",
    "correct_answer": "Option A",
    "context": "optional context"
  },
  {
    "question_id": "q_002",
    "question": "Explain Y",
    "answer_type": "short_answer",
    "user_answer": "My answer",
    "correct_answer": "Correct answer"
  }
]
```

#### Behavior & Output Format

**Success Flow**:

1. **Initialize Phase**:
   ```
   üöÄ Initializing Agent... (GEMINI_API_KEY required)
   ‚úÖ Agent initialized
   ```

2. **Loading Phase**:
   ```
   üìÇ Loading batch file...
      File: /path/to/batch.json
      Items: 5
   ‚úÖ Batch loaded
   ```

3. **Scoring Phase**:
   ```
   üîÑ Scoring answers in parallel...
      Workers: 3
      Processing: q_001, q_002, q_003, q_004, q_005
   ```

4. **Progress Display**:
   ```
   ‚è≥ Scoring progress: [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë] 8/10 (80%)
   ‚úÖ q_001: 100 (correct)
   ‚ö†Ô∏è  q_002: 65 (partial)
   ‚ùå q_003: 0 (incorrect)
   ```

5. **Results Summary**:
   ```
   ‚úÖ Batch Scoring Complete
      Total: 5 items
      Passed (100): 2
      Partial (50-99): 1
      Failed (0-49): 2
      Average Score: 73.0
      Execution Time: 2.34s
   ```

6. **Results Table** (Rich Table):
   ```
   üìä Batch Results:
   ‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
   ‚îÉ ID      ‚îÉ Type  ‚îÉ Score ‚îÉ Status‚îÉ
   ‚î£‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïã‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïã‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïã‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î´
   ‚îÉ q_001   ‚îÉ MC    ‚îÉ 100   ‚îÉ ‚úÖ   ‚îÉ
   ‚îÉ q_002   ‚îÉ SA    ‚îÉ 65    ‚îÉ ‚ö†Ô∏è   ‚îÉ
   ‚îÉ q_003   ‚îÉ T/F   ‚îÉ 0     ‚îÉ ‚ùå   ‚îÉ
   ‚îó‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îõ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îõ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îõ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îõ
   ```

7. **Optional Output File**:
   ```
   üìÅ Results saved to: /path/to/results.json
   ```

#### Error Handling

**Missing batch file**:
```
‚ùå Error: --batch-file is required
Usage: agent batch-score --batch-file FILE [--parallel N] [--output FILE]
```

**File not found**:
```
‚ùå Error: Batch file not found: /path/to/batch.json
```

**Invalid JSON format**:
```
‚ùå Error: Invalid JSON in batch file
Reason: [JSON parse error details]
```

**Empty batch**:
```
‚ùå Error: Batch file contains no items (empty array)
```

**Invalid item in batch**:
```
‚ùå Error: Item at index 2 missing required fields
Required: question_id, question, answer_type, user_answer, correct_answer
```

**Agent initialization failure**:
```
‚ùå Error: Agent initialization failed
Reason: GEMINI_API_KEY not found
```

**Parallel execution failure**:
```
‚ùå Error: Batch scoring failed
Items completed: 3/5
Failed items: q_004 (timeout), q_005 (API error)
```

#### Validation & Requirements

1. **Parameter Validation**:
   - `--batch-file`: Required, valid file path
   - `--parallel`: Optional, integer 1-10 (default: 3)
   - `--output`: Optional, valid file path for results

2. **Batch File Validation**:
   - Valid JSON array format
   - At least 1 item in batch
   - Each item has required fields: question_id, question, answer_type, user_answer, correct_answer
   - Optional field: context
   - answer_type must be one of: multiple_choice, short_answer, true_false

3. **Parallel Execution**:
   - Use asyncio.gather() for concurrent scoring
   - Configurable worker count (1-10, default 3)
   - Timeout per item: 30 seconds
   - Partial success: Continue scoring despite individual failures

4. **Results Output**:
   - Rich Table with ID, Type, Score, Status columns
   - Summary statistics: total, passed, partial, failed, average score
   - Execution time tracking
   - Optional JSON file export

5. **Environment**:
   - Require GEMINI_API_KEY (auto-loaded from .env)
   - Optional LANGCHAIN_DEBUG (1=verbose, 0=normal)

#### Dependencies

- **Internal**: REQ-A-Mode2-Tool6, ItemGenAgent, asyncio.gather()
- **External**: LangChain, Rich, Google Gemini API

---

## üß™ Phase 2: TEST DESIGN

### 2.1 Test Execution Strategy

Create `tests/cli/test_agent_batch_score.py` with:
- Unit tests for file parsing and validation
- Integration tests with mock ItemGenAgent
- Parallel execution tests
- Error handling tests for all failure modes
- Output formatting and file export tests

### 2.2 Test Cases

#### TC-1: Help Command Display
**Test**: `agent batch-score --help` shows usage
```python
def test_batch_score_help(mock_context: CLIContext) -> None:
    """TC-1: Verify --help displays command usage"""
    # Expected: Shows --batch-file, --parallel, --output options
```

#### TC-2: Missing Batch File Parameter
**Test**: Command without --batch-file returns error
```python
def test_missing_batch_file(mock_context: CLIContext) -> None:
    """TC-2: Verify error when --batch-file missing"""
```

#### TC-3: Batch File Not Found
**Test**: File path doesn't exist
```python
def test_batch_file_not_found(mock_context: CLIContext) -> None:
    """TC-3: Verify error for non-existent file"""
```

#### TC-4: Invalid JSON in Batch File
**Test**: Malformed JSON
```python
def test_invalid_json_format(mock_context: CLIContext) -> None:
    """TC-4: Verify error for invalid JSON"""
```

#### TC-5: Empty Batch Array
**Test**: JSON array with no items
```python
def test_empty_batch_array(mock_context: CLIContext) -> None:
    """TC-5: Verify error for empty batch"""
```

#### TC-6: Missing Required Fields in Item
**Test**: Item missing question_id or other required fields
```python
def test_missing_required_fields(mock_context: CLIContext) -> None:
    """TC-6: Verify error for incomplete item"""
```

#### TC-7: Successful Batch Scoring
**Test**: Complete batch with multiple items scored correctly
```python
def test_successful_batch_scoring(mock_context, mock_agent) -> None:
    """TC-7: Verify successful batch scoring"""
    # Expected: All items scored, summary displayed, progress tracked
```

#### TC-8: Partial Success (Some Failures)
**Test**: Batch with some items failing to score
```python
def test_partial_success_batch(mock_context, mock_agent) -> None:
    """TC-8: Verify handling of partial failures"""
    # Expected: Continue scoring, show summary with failed items
```

#### TC-9: Parallel Execution Performance
**Test**: Verify concurrent execution improves performance
```python
def test_parallel_execution_performance(mock_context, mock_agent) -> None:
    """TC-9: Verify parallel execution reduces time"""
    # Expected: Multiple workers executing concurrently
```

#### TC-10: Output File Export
**Test**: Results exported to JSON file
```python
def test_output_file_export(mock_context, mock_agent) -> None:
    """TC-10: Verify results saved to file"""
    # Expected: Valid JSON file with all results
```

#### TC-11: Custom Parallel Workers
**Test**: --parallel flag with custom worker count
```python
def test_custom_parallel_workers(mock_context, mock_agent) -> None:
    """TC-11: Verify custom worker count"""
    # Expected: Use specified number of workers
```

#### TC-12: Agent Initialization Failure
**Test**: GEMINI_API_KEY not found
```python
def test_agent_init_failure(mock_context) -> None:
    """TC-12: Verify error when API key missing"""
```

### 2.3 Test Implementation Structure

**File**: `tests/cli/test_agent_batch_score.py` (~500 LOC)

**Fixtures**:
- `mock_context`: CLIContext with buffered console
- `mock_agent`: Mock ItemGenAgent with score_answer method
- `batch_file`: Temporary JSON batch file
- `mock_score_responses`: Multiple ScoreAnswerResponse objects

**Test Classes**:
- `TestBatchScoreHelpAndErrors` (TC-1 through TC-6, TC-12)
- `TestBatchScoreSuccess` (TC-7 through TC-11)

**Mocking Strategy**:
- Mock `src.cli.actions.agent.ItemGenAgent` constructor
- Mock `agent.score_answer()` with AsyncMock
- Return different scores for different items
- Simulate network delays to test parallel execution
- Temporary files for batch input/output

### 2.4 Acceptance Criteria (Phase 2)

- [x] 12 test cases designed with clear assertions
- [x] Mock strategy defined for external dependencies
- [x] Test file location and class structure identified
- [x] Fixture setup documented
- [ ] **PENDING**: User approval to proceed to Phase 3

---

## üíª Phase 3: IMPLEMENTATION ‚úÖ COMPLETE

### 3.1 Implementation Summary

Implemented `batch_score` command with complete functionality:

1. **src/cli/actions/agent.py**:
   - Replaced placeholder `batch_score()` function (288 lines)
   - Implemented `_print_batch_score_help()` helper (52 lines)
   - Full argument parsing: --batch-file, --parallel (1-10, default 3), --output
   - Batch file validation: JSON array, required fields, answer_type enum
   - Parallel execution using asyncio.gather() with configurable workers
   - Rich Table output with results summary and statistics
   - Optional JSON file export with metadata

2. **tests/cli/test_agent_batch_score.py** ‚úÖ ALL TESTS PASSING (15/15):
   - **Help & Error Tests** (9 tests):
     - TC-1: --help displays command usage
     - TC-2: Missing --batch-file error
     - TC-3: File not found error
     - TC-4: Invalid JSON format error
     - TC-5: Empty batch array error
     - TC-6: Missing required fields error
     - TC-7: Invalid answer_type error
     - TC-8: Invalid parallel workers error
     - TC-9: Agent initialization failure error
   - **Success Tests** (6 tests):
     - TC-10: Successful batch scoring (2 items)
     - TC-11: Partial success handling (mixed results)
     - TC-12: Custom parallel worker count
     - TC-13: Output file JSON export
     - TC-14: Results table display (all status types)
     - TC-15: Optional context field handling

### 3.2 Key Implementation Details

**Parallel Execution Pattern**:
```python
async def score_batch_parallel():
    tasks = [score_single_item(item) for item in batch_data]

    # Execute with limited concurrency
    for i in range(0, len(tasks), parallel_workers):
        chunk = tasks[i : i + parallel_workers]
        chunk_results = await asyncio.gather(*chunk)
        # Process results with progress tracking
```

**Error Handling**:
- Comprehensive validation at each stage (parse, load, validate, score)
- Partial success: Continue scoring despite individual item failures
- Results aggregation with per-item error tracking

**Output Format**:
- Progress bar during scoring (transient Rich output)
- Summary statistics (total, passed, partial, failed, average score, execution time)
- Rich Table with ID, Type, Score, Status columns
- Optional JSON export with metadata and error details

---

## üìä Phase 3-4 Results

| Phase | Task | Status | Details |
|-------|------|--------|---------|
| 1 | Specification ‚úì | ‚úÖ Complete | Comprehensive spec with parallel execution |
| 2 | Test Design ‚úì | ‚úÖ Complete | 15 test cases with mocking strategy |
| 3 | Implementation ‚úì | ‚úÖ Complete | Full feature with tests (15/15 passing) |
| 4 | Commit & Docs | ‚úÖ Complete | Progress documented, ready for commit |

---

## üìù Traceability Matrix

### Implementation ‚Üí Test Coverage

| Component | Test Coverage |
|-----------|--------------|
| Help command (--help) | TC-1 ‚úÖ |
| Argument validation | TC-2, TC-8 ‚úÖ |
| File handling | TC-3, TC-4, TC-5 ‚úÖ |
| Batch validation | TC-6, TC-7 ‚úÖ |
| Agent initialization | TC-9 ‚úÖ |
| Parallel scoring | TC-10, TC-11, TC-12 ‚úÖ |
| Output formatting | TC-13, TC-14 ‚úÖ |
| Optional fields | TC-15 ‚úÖ |

### Code Statistics

- **batch_score()**: 288 lines
- **_print_batch_score_help()**: 52 lines
- **tests/cli/test_agent_batch_score.py**: 486 lines
- **Test Coverage**: 15 tests, all passing (2.43s execution)
- **Error Scenarios**: 9 comprehensive error tests

---

## ‚úÖ Phase 1-4 Complete

- Phase 1: ‚úì Comprehensive specification with parallel execution details
- Phase 2: ‚úì 15 detailed test cases with mocking strategy (15/15 passing)
- Phase 3: ‚úì Full implementation with parallel batch scoring
- Phase 4: ‚úì Documentation complete, git commit: **719d5c4**

### Git Commit Details

**Commit SHA**: `719d5c4`
**Message**: `feat(cli-agent): Implement REQ-CLI-Agent-4 - agent batch-score command`

**Changes**:
- Modified: src/cli/actions/agent.py (340 lines total: 288 + 52)
- Created: tests/cli/test_agent_batch_score.py (486 lines)
- Created: docs/progress/REQ-CLI-Agent-4.md (449 lines)
- Modified: docs/DEV-PROGRESS.md (updated status and commit)

**Statistics**:
- Total insertions: 1266 lines
- Test coverage: 15 tests (100% passing)
- Execution time: 2.43s
- Error handling: 9 comprehensive error scenarios
