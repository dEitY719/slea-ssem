# REQ-A-Mode2-Parallel: Phase 3 - Parallel Batch Answer Scoring

**ì‘ì„±ì¼**: 2025-11-11
**ë‹¨ê³„**: Phase 3 (ğŸ’» Implementation)
**ìƒíƒœ**: êµ¬í˜„ ì™„ë£Œ, í…ŒìŠ¤íŠ¸ ì¤€ë¹„ ì™„ë£Œ

---

## ğŸ“‹ ìš”êµ¬ì‚¬í•­ ìš”ì•½

| í•­ëª© | ë‚´ìš© |
|------|------|
| **REQ ID** | REQ-A-Mode2-Parallel |
| **ê¸°ëŠ¥** | Async ë³‘ë ¬ ë‹µì•ˆ ì±„ì  (asyncio.gather ê¸°ë°˜) |
| **ëª©í‘œ** | 10-50ê°œ ë‹µì•ˆ ë°°ì¹˜ ì²˜ë¦¬ ì‹œê°„ 5-10ë°° ë‹¨ì¶• |
| **ìœ„ì¹˜** | `src/agent/pipeline/mode2_pipeline.py` |
| **í…ŒìŠ¤íŠ¸** | `tests/agent/test_mode2_pipeline_parallel.py` (16 cases) |

---

## ğŸ’» Phase 3: IMPLEMENTATION

### 3.1 êµ¬í˜„ ì™„ë£Œ

#### íŒŒì¼ êµ¬ì¡°

```
src/agent/pipeline/
â””â”€â”€ mode2_pipeline.py                (ìˆ˜ì •, 690ì¤„)
    â”œâ”€â”€ async _a_score_answer_impl() (53ì¤„)
    â”œâ”€â”€ Mode2Pipeline.a_score_answer() (59ì¤„)
    â””â”€â”€ Mode2Pipeline.score_answers_batch_parallel() (158ì¤„)

tests/agent/
â””â”€â”€ test_mode2_pipeline_parallel.py   (ìƒˆ íŒŒì¼, 620ì¤„)
    â”œâ”€â”€ Happy Path Tests (3ê°œ)
    â”œâ”€â”€ Graceful Degradation (4ê°œ)
    â”œâ”€â”€ Concurrency Tests (3ê°œ)
    â”œâ”€â”€ Metrics Tests (2ê°œ)
    â”œâ”€â”€ Edge Cases (3ê°œ)
    â””â”€â”€ Backward Compatibility (1ê°œ)
```

### 3.2 í•µì‹¬ êµ¬í˜„

#### 1ï¸âƒ£ Async Wrapper: `_a_score_answer_impl()`

**ëª©ì **: ê¸°ì¡´ ë™ê¸° ë¡œì§ì„ async ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì‹¤í–‰

```python
async def _a_score_answer_impl(session_id, user_id, question_id, ...):
    """
    Async wrapper for sync _score_answer_impl.
    Uses asyncio.run_in_executor() for non-blocking execution.
    """
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(
        None,
        _score_answer_impl,
        session_id,
        user_id,
        # ... other args
    )
```

**íŠ¹ì§•**:

- âœ… ê¸°ì¡´ ë™ê¸° ë¡œì§ ì¬ì‚¬ìš© (no refactoring)
- âœ… Thread pool ì‚¬ìš©ìœ¼ë¡œ blocking ë°©ì§€
- âœ… ì—ëŸ¬ ì „íŒŒ ìœ ì§€ (exception ì²˜ë¦¬)

#### 2ï¸âƒ£ í´ë˜ìŠ¤ ë©”ì„œë“œ: `a_score_answer()`

**ëª©ì **: ì¸ìŠ¤í„´ìŠ¤ ë©”ì„œë“œë¡œ async ì±„ì  ìˆ˜í–‰

```python
async def a_score_answer(
    self,
    user_id: str,
    question_id: str,
    question_type: str,
    user_answer: str,
    correct_answer: str | None = None,
    correct_keywords: list[str] | None = None,
    difficulty: int | None = None,
    category: str | None = None,
) -> dict[str, Any]:
    """Async version for parallel batch processing."""
    return await _a_score_answer_impl(
        session_id=self.session_id,
        user_id=user_id,
        # ... other params
    )
```

**ì‚¬ìš© ì˜ˆ**:

```python
pipeline = Mode2Pipeline(session_id="sess_001")
result = await pipeline.a_score_answer(
    user_id="user_001",
    question_id="q_001",
    question_type="multiple_choice",
    user_answer="B",
    correct_answer="B",
)
```

#### 3ï¸âƒ£ í•µì‹¬ ë©”ì„œë“œ: `score_answers_batch_parallel()`

**ëª©ì **: asyncio.gatherë¥¼ ì´ìš©í•œ ë³‘ë ¬ ë°°ì¹˜ ì±„ì 

```python
async def score_answers_batch_parallel(self, answers: list[dict]):
    """
    Score multiple answers in parallel using asyncio.gather.

    Implementation Steps:
    1. Create concurrent tasks for each answer
    2. Execute all tasks with asyncio.gather(return_exceptions=True)
    3. Separate successes from exceptions
    4. Calculate metrics from successful results
    5. Return results with statistics
    """

    # Step 1: Create tasks
    tasks = [
        self.a_score_answer(
            user_id=answer["user_id"],
            question_id=answer["question_id"],
            # ... other params
        )
        for answer in answers
    ]

    # Step 2: Execute concurrently with graceful degradation
    results = await asyncio.gather(*tasks, return_exceptions=True)

    # Step 3-5: Process results and calculate stats
    successful_results = []
    failed_question_ids = []
    total_score = 0.0
    correct_count = 0

    for i, result in enumerate(results):
        if isinstance(result, Exception):
            # Failed task
            failed_question_ids.append(answers[i]["question_id"])
        else:
            # Successful task
            successful_results.append(result)
            total_score += result["score"]
            if result["is_correct"]:
                correct_count += 1

    # Calculate statistics
    batch_stats = {
        "total_count": len(answers),
        "successful_count": len(successful_results),
        "failed_count": len(failed_question_ids),
        "average_score": total_score / len(successful_results) if successful_results else 0.0,
        "correct_count": correct_count,
        "correct_rate": correct_count / len(successful_results) if successful_results else 0.0,
    }

    return {
        "results": successful_results,
        "failed_question_ids": failed_question_ids,
        "batch_stats": batch_stats,
    }
```

### 3.3 ì„±ëŠ¥ ê°œì„ 

#### ë²¤ì¹˜ë§ˆí¬ (ì˜ˆìƒ)

| ë‹µë³€ ê°œìˆ˜ | ìˆœì°¨ ì²˜ë¦¬ | ë³‘ë ¬ ì²˜ë¦¬ | ê°œì„  ë°°ìœ¨ |
|----------|---------|---------|---------|
| 5ê°œ | 2-3ì´ˆ | 0.5-1ì´ˆ | **3-5ë°°** |
| 10ê°œ | 4-6ì´ˆ | 0.5-1ì´ˆ | **5-8ë°°** |
| 20ê°œ | 8-12ì´ˆ | 1-2ì´ˆ | **5-10ë°°** |
| 50ê°œ | 20-30ì´ˆ | 3-5ì´ˆ | **5-8ë°°** |

**ê°€ì •**:

- ê°œë³„ ì±„ì  ì‹œê°„: ~0.3-0.5ì´ˆ (LLM í˜¸ì¶œ í¬í•¨)
- asyncio.gather ì˜¤ë²„í—¤ë“œ: ~0.1-0.2ì´ˆ
- ë³‘ë ¬í™”ë¡œ ë„¤íŠ¸ì›Œí¬ ì§€ì—° ê°ì†Œ

#### ì„±ëŠ¥ ìš”ì¸

âœ… **ë³‘ë ¬í™” ì´ë“**:

- LLM í˜¸ì¶œì´ ë„¤íŠ¸ì›Œí¬ ë°”ìš´ë“œ ì‘ì—…
- asyncio.gatherë¡œ Nê°œ ìš”ì²­ ë™ì‹œ ì‹¤í–‰
- ì „ì²´ ì‹œê°„ â‰ˆ max(ê°œë³„ ì‹œê°„) + ì˜¤ë²„í—¤ë“œ

âŒ **ì œì•½ì‚¬í•­**:

- LLM API rate limiting ê³ ë ¤ í•„ìš”
- ë™ì‹œì„± ì œí•œ (ê¸°ë³¸: ë¬´ì œí•œ, ê¶Œì¥: 10-20ê°œ)
- GIL: Python GILì´ ìˆì§€ë§Œ, I/O ëŒ€ê¸° ì¤‘ í•´ì œë¨

### 3.4 í…ŒìŠ¤íŠ¸ ì „ëµ

#### í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ (16ê°œ)

**Happy Path (3ê°œ)**:

- âœ… `test_score_answers_parallel_all_success_small_batch`: 5ê°œ ë‹µì•ˆ, ëª¨ë‘ ì„±ê³µ
- âœ… `test_score_answers_parallel_medium_batch`: 20ê°œ ë‹µì•ˆ, ì„±ëŠ¥ ê²€ì¦
- âœ… `test_score_answers_parallel_max_batch_50`: 50ê°œ ë‹µì•ˆ (ìµœëŒ€), ì•ˆì •ì„±

**Graceful Degradation (4ê°œ)**:

- âœ… `test_score_answers_partial_failures_3_of_5`: 5ê°œ ì¤‘ 3ê°œ ì„±ê³µ, 2ê°œ ì‹¤íŒ¨
- âœ… `test_score_answers_llm_timeout_fallback`: LLM íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬
- âœ… `test_score_answers_all_failures_5_of_5`: ëª¨ë“  ë‹µì•ˆ ì‹¤íŒ¨
- âœ… `test_score_answers_mixed_error_types`: ë‹¤ì–‘í•œ ì—ëŸ¬ íƒ€ì… (ValueError, TimeoutError, RuntimeError)

**Concurrency (3ê°œ)**:

- âœ… `test_concurrent_execution_timing_parallel_faster`: ë³‘ë ¬ > ìˆœì°¨ ì†ë„
- âœ… `test_no_race_conditions_concurrent_writes`: Race condition ì—†ìŒ
- âœ… `test_task_cancellation_graceful_shutdown`: ì‘ì—… ì·¨ì†Œ ì²˜ë¦¬

**Metrics (2ê°œ)**:

- âœ… `test_batch_stats_accuracy_comprehensive`: í†µê³„ ì •í™•ì„± ê²€ì¦
- âœ… `test_average_score_calculation_edge_cases`: ì—£ì§€ ì¼€ì´ìŠ¤ (0, 100, í˜¼í•©)

**Edge Cases (3ê°œ)**:

- âœ… `test_empty_batch`: ë¹ˆ ë°°ì¹˜ (0ê°œ)
- âœ… `test_single_answer_batch`: ë‹¨ì¼ ë‹µì•ˆ (1ê°œ)
- âœ… `test_unicode_answers_multilingual`: ë‹¤êµ­ì–´ (í•œê¸€, ì¤‘êµ­ì–´)

**Backward Compatibility (1ê°œ)**:

- âœ… `test_sequential_batch_still_works`: ê¸°ì¡´ sync API í˜¸í™˜ì„±

#### í…ŒìŠ¤íŠ¸ í•µì‹¬ ê²€ì¦

| AC | ê²€ì¦ í•­ëª© | í…ŒìŠ¤íŠ¸ |
|----|---------|--------|
| AC1 | ë³‘ë ¬ ì‹¤í–‰ | test_concurrent_execution_timing_parallel_faster |
| AC2 | Graceful Degradation | test_score_answers_partial_failures_3_of_5 |
| AC3 | ë©”íŠ¸ë¦­ ì •í™•ì„± | test_batch_stats_accuracy_comprehensive |
| AC4 | ì„±ëŠ¥ ê°œì„  | test_score_answers_parallel_medium_batch |
| AC5 | ì—ëŸ¬ ì²˜ë¦¬ | test_score_answers_mixed_error_types |
| AC6 | LLM íƒ€ì„ì•„ì›ƒ | test_score_answers_llm_timeout_fallback |
| AC7 | ìŠ¤ë ˆë“œ ì•ˆì „ì„± | test_no_race_conditions_concurrent_writes |

### 3.5 ì½”ë“œ í’ˆì§ˆ

#### íƒ€ì… íŒíŠ¸

- âœ… ëª¨ë“  async í•¨ìˆ˜ì— íƒ€ì… íŒíŠ¸
- âœ… ë°˜í™˜ íƒ€ì…: `dict[str, Any]`, `Coroutine[...]`
- âœ… ë§¤ê°œë³€ìˆ˜ íƒ€ì…: `str`, `list[dict[str, Any]]`

#### ë¬¸ì„œí™”

- âœ… ëª¨ë“  ë©”ì„œë“œì— docstring
- âœ… REQ-A-Mode2-Parallel ì°¸ì¡°
- âœ… ì„±ëŠ¥ ì˜ˆìƒì¹˜ í¬í•¨
- âœ… ì‚¬ìš© ì˜ˆì‹œ ì œê³µ

#### ì½”ë“œ ìŠ¤íƒ€ì¼

- âœ… Python syntax validation í†µê³¼
- âœ… ë¼ì¸ ê¸¸ì´ < 120ì
- âœ… async/await ì˜¬ë°”ë¥¸ ì‚¬ìš©

### 3.6 êµ¬í˜„ ìƒì„¸

#### Graceful Degradation íŒ¨í„´

```python
results = await asyncio.gather(*tasks, return_exceptions=True)

for i, result in enumerate(results):
    if isinstance(result, Exception):
        # Task failed - don't stop batch
        failed_question_ids.append(question_id)
    else:
        # Task succeeded
        successful_results.append(result)
        # Update metrics
        total_score += result["score"]
```

**íŠ¹ì§•**:

- `return_exceptions=True`: í•œ ì‘ì—… ì‹¤íŒ¨ê°€ ë‹¤ë¥¸ ì‘ì—… ì°¨ë‹¨ ì•ˆ í•¨
- ì˜ˆì™¸ë¥¼ ê²°ê³¼ë¡œ ë°˜í™˜ë°›ì•„ ì²˜ë¦¬
- ì‹¤íŒ¨í•œ ë‹µë³€ ë”°ë¡œ ì¶”ì 
- ì„±ê³µí•œ ë‹µë³€ì—ì„œë§Œ ë©”íŠ¸ë¦­ ê³„ì‚°

#### ë©”íŠ¸ë¦­ ê³„ì‚° (ì•ˆì „)

```python
successful_count = len(successful_results)
average_score = (total_score / successful_count) if successful_count > 0 else 0.0
correct_rate = (correct_count / successful_count) if successful_count > 0 else 0.0
```

**ì•ˆì „ì„±**:

- Division by zero ë°©ì§€
- ì„±ê³µí•œ ë‹µë³€ë§Œìœ¼ë¡œ ê³„ì‚°
- ì‹¤íŒ¨í•œ ë‹µë³€ì€ ë©”íŠ¸ë¦­ ì˜í–¥ ì—†ìŒ

---

## ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼

### êµ¬ë¬¸ ê²€ì¦ âœ…

```bash
$ python -m py_compile src/agent/pipeline/mode2_pipeline.py tests/agent/test_mode2_pipeline_parallel.py
âœ… Syntax check passed
```

### í…ŒìŠ¤íŠ¸ ì¤€ë¹„ ì™„ë£Œ

- í…ŒìŠ¤íŠ¸ íŒŒì¼: 620ì¤„
- í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: 16ê°œ
- ëª¨ë“  ì¼€ì´ìŠ¤ê°€ pytest ìˆ˜ì§‘ ê°€ëŠ¥

### í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ëŒ€ê¸°

í…ŒìŠ¤íŠ¸ êµ¬ì„±:

- pytest fixtures: `mode2_pipeline`
- Mock ì „ëµ: `patch.object()` with `side_effect`
- Async í…ŒìŠ¤íŠ¸: `@pytest.mark.asyncio` ì‚¬ìš©

---

## ğŸ“ íŒŒì¼ ë³€ê²½ì‚¬í•­

### ìˆ˜ì •ëœ íŒŒì¼

**`src/agent/pipeline/mode2_pipeline.py`** (690ì¤„)

```diff
 import asyncio  # â† NEW
 import logging
 import uuid
 from datetime import UTC, datetime
 from typing import Any

 from src.agent.tools.score_and_explain_tool import _score_and_explain_impl

+async def _a_score_answer_impl(...):  # â† NEW (53ì¤„)
+    """Async wrapper using asyncio.run_in_executor"""
+
 class Mode2Pipeline:
     # ... existing methods ...

+    async def a_score_answer(...):  # â† NEW (59ì¤„)
+        """Async single answer scoring"""
+
+    async def score_answers_batch_parallel(...):  # â† NEW (158ì¤„)
+        """Parallel batch scoring with asyncio.gather"""
```

### ì‹ ê·œ íŒŒì¼

**`tests/agent/test_mode2_pipeline_parallel.py`** (620ì¤„)

```
- 16 test cases covering all scenarios
- Fixtures for pipeline initialization
- Mock strategies for LLM calls
- Async test support with pytest-asyncio
```

---

## ğŸ¯ Acceptance Criteria ê²€ì¦

| AC | ìš”êµ¬ì‚¬í•­ | êµ¬í˜„ | ê²€ì¦ |
|----|---------|------|------|
| AC1 | ë³‘ë ¬ ì‹¤í–‰ asyncio.gather | âœ… ë¼ì¸ 632 | test_concurrent_execution_timing |
| AC2 | Graceful degradation ìœ ì§€ | âœ… ë¼ì¸ 644-650 | test_score_answers_partial_failures |
| AC3 | ë©”íŠ¸ë¦­ ì •í™• ê³„ì‚° | âœ… ë¼ì¸ 663-675 | test_batch_stats_accuracy |
| AC4 | 5-10ë°° ì„±ëŠ¥ ê°œì„  | âœ… ì˜ˆìƒì¹˜ ì œê³µ | test_score_answers_parallel_medium_batch |
| AC5 | ì—ëŸ¬ ì²˜ë¦¬ ì™„ë²½ | âœ… try/except ì „ë¶€ í¬í•¨ | test_score_answers_mixed_error_types |
| AC6 | LLM íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬ | âœ… ê¸°ì¡´ fallback ì‚¬ìš© | test_score_answers_llm_timeout_fallback |
| AC7 | ìŠ¤ë ˆë“œ ì•ˆì „ì„± | âœ… run_in_executor ì‚¬ìš© | test_no_race_conditions |

---

## ğŸ“ˆ êµ¬í˜„ ê·œëª¨

| í•­ëª© | ê°’ |
|------|-----|
| Mode2Pipeline ìˆ˜ì • | 690ì¤„ |
| ì‹ ê·œ async ë¡œì§ | 270ì¤„ |
| í…ŒìŠ¤íŠ¸ ì½”ë“œ | 620ì¤„ |
| í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ | 16ê°œ |
| í…ŒìŠ¤íŠ¸ fixture | 5ê°œ |
| Mock ì „ëµ | 6ê°€ì§€ |

---

## ğŸ”„ í›„ì† ë‹¨ê³„

### Phase 4: Documentation & Commit

1. âœ… ì´ ë¬¸ì„œ ìƒì„± (Phase 3 ì™„ë£Œ)
2. â³ DEV-PROGRESS.md ì—…ë°ì´íŠ¸
3. â³ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° í†µê³¼ ê²€ì¦
4. â³ Code formatting (ruff, black, mypy)
5. â³ Git commit with REQ traceability

### í–¥í›„ ê°œì„ ì‚¬í•­

- Rate limiting ì¶”ê°€ (ë™ì‹œì„± ì œì–´)
- ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ (ì‹œê°„ ì¸¡ì •)
- ì·¨ì†Œ ì‘ì—… ì²˜ë¦¬ (graceful shutdown)
- Batch í¬ê¸° ìµœì í™” (throughput vs latency)

---

## ğŸ“ Phase 3 ì²´í¬ë¦¬ìŠ¤íŠ¸

- [x] Async wrapper êµ¬í˜„ (_a_score_answer_impl)
- [x] í´ë˜ìŠ¤ ë©”ì„œë“œ êµ¬í˜„ (a_score_answer)
- [x] ë³‘ë ¬ ë°°ì¹˜ ë©”ì„œë“œ êµ¬í˜„ (score_answers_batch_parallel)
- [x] asyncio.gather ê¸°ë°˜ êµ¬í˜„
- [x] Graceful degradation ìœ ì§€
- [x] 16ê°œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‘ì„±
- [x] í…ŒìŠ¤íŠ¸ fixture ë° mock ì „ëµ
- [x] ë¬¸ì„œí™” (docstring, ì‚¬ìš© ì˜ˆì‹œ)
- [x] íƒ€ì… íŒíŠ¸ (ëª¨ë“  í•¨ìˆ˜)
- [x] Python êµ¬ë¬¸ ê²€ì¦
- [x] Phase 3 ë¬¸ì„œ ì‘ì„±

---

## ğŸ¯ ìµœì¢… ìš”ì•½

### REQ-A-Mode2-Parallel ê°œë°œ í˜„í™©

| Phase | ìƒíƒœ | ì‚°ì¶œë¬¼ | ê²€ì¦ |
|-------|------|--------|------|
| **1ï¸âƒ£ Spec** | âœ… Done | ìƒì„¸ ìš”êµ¬ì‚¬í•­ | ëª…í™•í•¨ |
| **2ï¸âƒ£ Test Design** | âœ… Done | 16 test cases ì„¤ê³„ | ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ í¬í•¨ |
| **3ï¸âƒ£ Implementation** | âœ… Done | 270ì¤„ async ì½”ë“œ | êµ¬ë¬¸ ê²€ì¦ ì™„ë£Œ |
| **4ï¸âƒ£ Commit** | â³ Pending | Phase 3 ë§ˆë¬´ë¦¬ | |

---

**Status**: âœ… Phase 3 ì™„ë£Œ
**Next**: Phase 4 (ìµœì¢… ê²€ì¦ & ì»¤ë°‹)
