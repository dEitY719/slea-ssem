# Agent ê°•ê±´ì„± ê°œì„  ê³„íš (enhance_robust_agent_A)

> **Version**: 1.1 (Updated with G, CX feedback)
> **Last Updated**: 2025-12-05

## 0. ë™ë£Œ í”¼ë“œë°± ë°˜ì˜ ìš”ì•½

### ë°˜ì˜ëœ í•µì‹¬ ì¸ì‚¬ì´íŠ¸

| ì¶œì²˜ | í•µì‹¬ ì œì•ˆ | ë°˜ì˜ ìœ„ì¹˜ |
|------|-----------|-----------|
| **G ë¬¸ì„œ** | `with_structured_output` í™œìš©ìœ¼ë¡œ ìˆ˜ë™ íŒŒì‹± ì œê±° | Phase 0 (ì‹ ê·œ) |
| **G ë¬¸ì„œ** | Two-Step "Gather-Then-Generate" ë‹¨ìˆœí™” | Phase 0 (ì‹ ê·œ) |
| **G ë¬¸ì„œ** | í”„ë¡¬í”„íŠ¸ ëŒ€í­ ë‹¨ìˆœí™” | Phase 3.2 ê°•í™” |
| **CX ë¬¸ì„œ** | `StructuredTool` with `args_schema` | Phase 2 (ì‹ ê·œ Task) |
| **CX ë¬¸ì„œ** | `ActionSanitizer` ì „ì²˜ë¦¬ ë‹¨ê³„ | Phase 2 (ì‹ ê·œ Task) |
| **CX ë¬¸ì„œ** | `parse_json_robust()` ì „ì—­ í™œìš© | Phase 2 ê°•í™” |
| **CX ë¬¸ì„œ** | `src/agent/tests` ë¹„ì–´ìˆìŒ | Phase 4 ê°•í™” |
| **CX ë¬¸ì„œ** | êµ¬ì¡°í™”ëœ ë¡œê¹… í•„ìš” | Phase 4 (ì‹ ê·œ Task) |

---

## 1. ë¬¸ì œ ìš”ì•½

### 1.1 í˜„ìƒ
| í™˜ê²½ | ëª¨ë¸ | ìƒíƒœ |
|------|------|------|
| ì‚¬ì™¸PC (ê³µê°œë§) | gemini-2.0-flash | ì •ìƒ ë™ì‘ |
| ì‚¬ë‚´PC (íì‡„ë§) | deepseek-v3-0324 | ì˜¤ë™ì‘ |

### 1.2 ì¦ìƒ
- **Tool í˜¸ì¶œ í˜•ì‹ ë¬¸ì œ**: DeepSeekì´ JSON ëŒ€ì‹  XML í˜•íƒœë¡œ ë„êµ¬ í˜¸ì¶œ
- **Output í˜•ì‹ ë¶ˆì¼ì¹˜**: ëª¨ë¸ì´ ì•½ì†ëœ ReAct í˜•ì‹ì„ ì¤€ìˆ˜í•˜ì§€ ì•ŠìŒ
- **Structured Output ë¯¸ì§€ì›**: DeepSeek-v3ê°€ `response_format: json_schema` ë¯¸ì§€ì›

### 1.3 ê·¼ë³¸ ì›ì¸ ë¶„ì„

```
í˜„ì¬ ì•„í‚¤í…ì²˜ (Gemini ìµœì í™”):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  create_react_agent (LangGraph v2)                          â”‚
â”‚  â”œâ”€â”€ Tool Calling: ëª¨ë¸ì˜ native tool_calls ê¸°ëŠ¥ ì‚¬ìš©        â”‚
â”‚  â”œâ”€â”€ Response Format: JSON structured output                â”‚
â”‚  â””â”€â”€ Prompt: ReAct í…ìŠ¤íŠ¸ í˜•ì‹ (Thought/Action/Observation)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“ Gemini: ì •ìƒ â†“ DeepSeek: ì‹¤íŒ¨
```

**í•µì‹¬ ë¬¸ì œì :**
1. LangGraph `create_react_agent`ëŠ” ëª¨ë¸ì˜ native **Tool Calling API**ë¥¼ ì‚¬ìš©
2. DeepSeek-v3ëŠ” OpenAI-compatible tool callingì„ ì œí•œì ìœ¼ë¡œ ì§€ì›
3. í”„ë¡¬í”„íŠ¸ëŠ” í…ìŠ¤íŠ¸ ê¸°ë°˜ ReAct í˜•ì‹ì´ì§€ë§Œ, ì‹¤ì œ ì‹¤í–‰ì€ Tool Callingì— ì˜ì¡´
4. ëª¨ë¸ ê°„ Tool Calling ì§€ì› ìˆ˜ì¤€ ì°¨ì´ë¡œ ì¸í•œ ë¶ˆì¼ì¹˜

---

## 2. ì½”ë“œ ë¶„ì„ ê²°ê³¼

### 2.1 í˜„ì¬ ì•„í‚¤í…ì²˜ (`src/agent/`)

```
src/agent/
â”œâ”€â”€ llm_agent.py          # í•µì‹¬: ItemGenAgent (create_react_agent ì‚¬ìš©)
â”œâ”€â”€ config.py             # LLM Provider íŒ©í† ë¦¬ (Strategy Pattern)
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ react_prompt.py   # í”„ë¡¬í”„íŠ¸ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
â”‚   â”œâ”€â”€ prompt_content.py # ReAct í˜•ì‹ ê·œì¹™ (í…ìŠ¤íŠ¸)
â”‚   â””â”€â”€ prompt_builder.py # Builder Pattern
â”œâ”€â”€ tools/                # 6ê°œ Tool êµ¬í˜„ (@tool ë°ì½”ë ˆì´í„°)
â”œâ”€â”€ output_converter.py   # Final Answer JSON íŒŒì‹±
â””â”€â”€ fastmcp_server.py     # Tool ëª©ë¡ ë“±ë¡
```

### 2.2 ë¬¸ì œê°€ ë˜ëŠ” ì½”ë“œ ì˜ì—­

#### A. `llm_agent.py:370-376` - Agent ìƒì„±
```python
# ë¬¸ì œ: create_react_agentëŠ” ëª¨ë¸ì˜ Tool Callingì„ ìë™ìœ¼ë¡œ ì‚¬ìš©
self.executor = create_react_agent(
    model=self.llm,
    tools=self.tools,
    prompt=self.prompt,
    debug=AGENT_CONFIG.get("verbose", False),
    version="v2",  # LangGraph v2
)
```

**ë¬¸ì œì **: DeepSeekì´ Tool Callingì„ ì œëŒ€ë¡œ ì§€ì›í•˜ì§€ ì•Šìœ¼ë©´ ì „ì²´ íŒŒì´í”„ë¼ì¸ì´ ì‹¤íŒ¨

#### B. `config.py:79-119` - LiteLLM Provider
```python
class LiteLLMProvider(LLMProvider):
    def create(self) -> ChatOpenAI:
        return ChatOpenAI(
            model=model,
            api_key=api_key,
            base_url=base_url,
            temperature=0.3,
            max_tokens=8192,
            timeout=30,
        )
```

**ë¬¸ì œì **: DeepSeek-v3ì˜ íŠ¹ì„± (tool calling ì œí•œ, json_schema ë¯¸ì§€ì›)ì„ ê³ ë ¤í•˜ì§€ ì•ŠìŒ

#### C. `prompt_content.py` - ReAct í”„ë¡¬í”„íŠ¸
```
í˜„ì¬ í”„ë¡¬í”„íŠ¸ ì„¤ê³„:
- í…ìŠ¤íŠ¸ ê¸°ë°˜ ReAct í˜•ì‹ ëª…ì‹œ (Thought/Action/Action Input/Observation)
- ê·¸ëŸ¬ë‚˜ ì‹¤ì œ ì‹¤í–‰ì€ LangGraphì˜ Tool Calling ë©”ì»¤ë‹ˆì¦˜ì— ì˜ì¡´
- ëª¨ë¸ì´ í…ìŠ¤íŠ¸ í˜•ì‹ì„ ë¬´ì‹œí•˜ê³  XMLì´ë‚˜ ë‹¤ë¥¸ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•  ìˆ˜ ìˆìŒ
```

### 2.3 ì°¸ì¡° ë¬¸ì„œ ë°œê²¬

| ë¬¸ì„œ | ê²½ë¡œ | ë‚´ìš© |
|------|------|------|
| Postmortem 1 | `docs/postmortem-prompt-escaping-solid-refactoring.md` | JSON ì´ìŠ¤ì¼€ì´í•‘ ë¬¸ì œ í•´ê²° |
| Postmortem 2 | (ëˆ„ë½) | LiteLLM "No tool results" ì—ëŸ¬ ë¶„ì„ í•„ìš” |
| SOLID Refactoring | `docs/PROMPT_SOLID_REFACTORING.md` | í”„ë¡¬í”„íŠ¸ ì•„í‚¤í…ì²˜ ê°œì„  |

---

## 3. ê°œì„  ì „ëµ

### 3.1 ì „ëµ ê°œìš”

```
ê°œì„ ëœ ì•„í‚¤í…ì²˜ (Multi-Model ì§€ì›) - v1.1:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AgentRunner (ìƒˆë¡œìš´ Facade)                                â”‚
â”‚  â”œâ”€â”€ ModelCapabilityProfile: ëª¨ë¸ ëŠ¥ë ¥ í”„ë¡œíŒŒì¼             â”‚
â”‚  â”‚   â”œâ”€â”€ supports_tool_calls: bool                         â”‚
â”‚  â”‚   â”œâ”€â”€ supports_json_mode: bool                          â”‚
â”‚  â”‚   â””â”€â”€ needs_react_text: bool                            â”‚
â”‚  â”œâ”€â”€ AgentFactory: ëª¨ë¸ì— ë§ëŠ” Agent ìƒì„±                    â”‚
â”‚  â”‚   â”œâ”€â”€ StructuredOutputAgent (Gemini, GPT-4) â† NEW       â”‚
â”‚  â”‚   â”œâ”€â”€ ToolCallingAgent (Gemini, GPT-4)                  â”‚
â”‚  â”‚   â””â”€â”€ TextReActAgent (DeepSeek, ê¸°íƒ€)                   â”‚
â”‚  â”œâ”€â”€ ActionSanitizer: XML/YAML â†’ JSON ì „ì²˜ë¦¬ â† NEW         â”‚
â”‚  â”œâ”€â”€ OutputNormalizer: ë‹¤ì–‘í•œ ì¶œë ¥ í˜•ì‹ ì •ê·œí™”               â”‚
â”‚  â””â”€â”€ StructuredLogging: ë””ë²„ê¹…ìš© êµ¬ì¡°í™” ë¡œê·¸ â† NEW          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 Phase 0: ê·¼ë³¸ì  í•´ê²°ì±… - Structured Output (G ë¬¸ì„œ ë°˜ì˜) â­ NEW

> **í•µì‹¬ ì•„ì´ë””ì–´**: ìˆ˜ë™ Final Answer íŒŒì‹±ì„ ì œê±°í•˜ê³ , LangChainì˜ `with_structured_output`ì„ í™œìš©í•˜ì—¬ ëª¨ë¸ì— ê´€ê³„ì—†ì´ ì¼ê´€ëœ ì¶œë ¥ ë³´ì¥

#### Task 0.1: `with_structured_output` ë„ì…
- ëª©ì : ìˆ˜ë™ JSON íŒŒì‹± ì œê±°, ëª¨ë¸ë³„ ì°¨ì´ ì¶”ìƒí™”
- íŒŒì¼: `src/agent/llm_agent.py` (ìˆ˜ì •)

```python
# í˜„ì¬: ìˆ˜ë™ Final Answer íŒŒì‹±
def _parse_agent_output_generate(self, result, round_id):
    # ë³µì¡í•œ JSON ì¶”ì¶œ ë¡œì§...
    json_str = AgentOutputConverter.parse_final_answer_json(content)
    # ...

# ê°œì„ : with_structured_output ì‚¬ìš©
async def generate_questions(self, request) -> GenerateQuestionsResponse:
    # 1ë‹¨ê³„: ì •ë³´ ìˆ˜ì§‘ (ê¸°ì¡´ ë„êµ¬ í˜¸ì¶œ)
    context = await self._gather_context(request)

    # 2ë‹¨ê³„: Structured Outputìœ¼ë¡œ ìƒì„±
    structured_llm = self.llm.with_structured_output(GenerateQuestionsResponse)
    response = await structured_llm.ainvoke(
        f"Generate {request.question_count} questions based on: {context}"
    )

    # íŒŒì‹± ë¶ˆí•„ìš” - ì´ë¯¸ Pydantic ê°ì²´
    return response
```

**ì¥ì :**
- LangChainì´ ëª¨ë¸ë³„ ì°¨ì´ë¥¼ ë‚´ë¶€ì ìœ¼ë¡œ ì²˜ë¦¬ (JSON mode, function calling ë“±)
- `_parse_agent_output_generate`, `parse_json_robust` ë“± ë³µì¡í•œ íŒŒì‹± ë¡œì§ ì œê±° ê°€ëŠ¥
- íƒ€ì… ì•ˆì „ì„± ë³´ì¥

#### Task 0.2: Two-Step "Gather-Then-Generate" ì•„í‚¤í…ì²˜
- ëª©ì : ë³µì¡í•œ ReAct ë£¨í”„ ë‹¨ìˆœí™”, LLM í˜¸ì¶œ íšŸìˆ˜ ê°ì†Œ
- íŒŒì¼: `src/agent/llm_agent.py` (ìˆ˜ì •)

```python
class SimplifiedItemGenAgent:
    """
    Two-Step ì•„í‚¤í…ì²˜:
    1. Gather: ë„êµ¬ë¡œ ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘ (user_profile, keywords ë“±)
    2. Generate: with_structured_outputìœ¼ë¡œ ìµœì¢… ê²°ê³¼ ìƒì„±
    """

    async def generate_questions(self, request):
        # Step 1: Gather - ì •ë³´ ìˆ˜ì§‘ (ë„êµ¬ ì§ì ‘ í˜¸ì¶œ)
        profile = get_user_profile(request.user_id)
        keywords = get_difficulty_keywords(profile["self_level"], request.domain)

        context = {
            "profile": profile,
            "keywords": keywords,
            "domain": request.domain,
            "count": request.question_count,
        }

        # Step 2: Generate - êµ¬ì¡°í™”ëœ ì¶œë ¥ìœ¼ë¡œ ìƒì„±
        structured_llm = self.llm.with_structured_output(GenerateQuestionsResponse)
        response = await structured_llm.ainvoke(
            self._build_generation_prompt(context)
        )

        # Step 3: ê²€ì¦ ë° ì €ì¥ (Python ì½”ë“œë¡œ ì²˜ë¦¬, LLM ë£¨í”„ ë°–)
        validated_items = []
        for item in response.items:
            validation = validate_question_quality(item.stem, item.type, ...)
            if validation["is_valid"]:
                save_result = save_generated_question(...)
                validated_items.append(item)

        return GenerateQuestionsResponse(items=validated_items, ...)
```

**ì¥ì :**
- LLM í˜¸ì¶œ íšŸìˆ˜ ê°ì†Œ (10+ â†’ 2-3)
- ê²€ì¦/ì €ì¥ ë¡œì§ì´ Python ì½”ë“œë¡œ ì´ë™í•˜ì—¬ ì˜ˆì¸¡ ê°€ëŠ¥
- ReAct í˜•ì‹ ì¤€ìˆ˜ í•„ìš” ì—†ìŒ

#### Task 0.3: Pydantic ì‘ë‹µ ëª¨ë¸ ê°•í™”
- ëª©ì : ë„êµ¬ ì‘ë‹µë„ êµ¬ì¡°í™”
- íŒŒì¼: `src/agent/tools/*.py` (ìˆ˜ì •)

```python
# í˜„ì¬: dict ë°˜í™˜
@tool
def score_and_explain(...) -> dict[str, Any]:
    return {"is_correct": True, "score": 85, ...}

# ê°œì„ : Pydantic ëª¨ë¸ ë°˜í™˜ + with_structured_output ë‚´ë¶€ ì‚¬ìš©
class ScoreResult(BaseModel):
    is_correct: bool
    score: int = Field(ge=0, le=100)
    explanation: str
    keyword_matches: list[str] = []
    graded_at: str

def _call_llm_score_short_answer(...) -> ScoreResult:
    """LLM í˜¸ì¶œ ì‹œ with_structured_output ì‚¬ìš©"""
    structured_llm = llm.with_structured_output(ScoreResult)
    return structured_llm.invoke(prompt)
```

### 3.3 Phase 1: ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ ê°œì„  (Low Risk)

#### Task 1.1: ModelCapabilityDetector êµ¬í˜„
- ëª©ì : ëª¨ë¸ë³„ ì§€ì› ê¸°ëŠ¥ ìë™ ê°ì§€
- íŒŒì¼: `src/agent/model_capability.py` (ì‹ ê·œ)

```python
# êµ¬í˜„ ê°œë…
class ModelCapability:
    supports_tool_calling: bool = True
    supports_json_schema: bool = True
    supports_function_calling: bool = True
    preferred_react_format: str = "tool_calling"  # or "text"

MODEL_CAPABILITIES = {
    "gemini-2.0-flash": ModelCapability(
        supports_tool_calling=True,
        supports_json_schema=True,
        preferred_react_format="tool_calling"
    ),
    "deepseek-v3": ModelCapability(
        supports_tool_calling=False,  # ì œí•œì 
        supports_json_schema=False,
        preferred_react_format="text"
    ),
}

def detect_capability(model_name: str) -> ModelCapability:
    """ëª¨ë¸ ì´ë¦„ì—ì„œ capability ê°ì§€"""
    for pattern, capability in MODEL_CAPABILITIES.items():
        if pattern in model_name.lower():
            return capability
    return ModelCapability()  # ê¸°ë³¸ê°’ (Tool Calling ì‹œë„)
```

#### Task 1.2: TextReActAgent êµ¬í˜„ (Text-based ReAct)
- ëª©ì : Tool Calling ì—†ì´ ìˆœìˆ˜ í…ìŠ¤íŠ¸ ê¸°ë°˜ ReAct ì‹¤í–‰
- íŒŒì¼: `src/agent/text_react_agent.py` (ì‹ ê·œ)

```python
# êµ¬í˜„ ê°œë…
class TextReActAgent:
    """
    Tool Calling ì—†ì´ í…ìŠ¤íŠ¸ ê¸°ë°˜ ReActë¥¼ ì‹¤í–‰í•˜ëŠ” Agent.

    ë™ì‘ ë°©ì‹:
    1. í”„ë¡¬í”„íŠ¸ì— ë„êµ¬ ì„¤ëª… í¬í•¨ (í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ í˜•íƒœ)
    2. LLMì´ "Action: tool_name" í…ìŠ¤íŠ¸ë¡œ ì‘ë‹µ
    3. "Action Input: {...}" JSON íŒŒì‹±
    4. ë„êµ¬ ìˆ˜ë™ ì‹¤í–‰
    5. "Observation: ..." ì£¼ì…
    6. ë°˜ë³µ (Final Answerê¹Œì§€)
    """

    def __init__(self, llm, tools, prompt):
        self.llm = llm
        self.tools = {t.name: t for t in tools}
        self.prompt = prompt

    async def ainvoke(self, messages: list) -> dict:
        """í…ìŠ¤íŠ¸ ê¸°ë°˜ ReAct ì‹¤í–‰"""
        conversation = messages.copy()

        for iteration in range(MAX_ITERATIONS):
            # 1. LLM í˜¸ì¶œ
            response = await self.llm.ainvoke(conversation)
            content = response.content

            # 2. Final Answer ì²´í¬
            if "Final Answer:" in content:
                return {"messages": conversation + [response]}

            # 3. Action/Action Input íŒŒì‹±
            action, action_input = self._parse_action(content)

            # 4. ë„êµ¬ ì‹¤í–‰
            tool = self.tools.get(action)
            if tool:
                result = tool.invoke(action_input)
                observation = f"Observation: {json.dumps(result)}"
            else:
                observation = f"Observation: Tool '{action}' not found"

            # 5. Observation ì¶”ê°€
            conversation.append(response)
            conversation.append(HumanMessage(content=observation))

        return {"messages": conversation}

    def _parse_action(self, content: str) -> tuple[str, dict]:
        """í…ìŠ¤íŠ¸ì—ì„œ Action/Action Input íŒŒì‹±"""
        # "Action: tool_name" íŒŒì‹±
        action_match = re.search(r"Action:\s*(\w+)", content)
        action = action_match.group(1) if action_match else ""

        # "Action Input: {...}" íŒŒì‹± (JSON ë˜ëŠ” XML ëª¨ë‘ ì²˜ë¦¬)
        input_match = re.search(r"Action Input:\s*(.+?)(?=\n|$)", content, re.DOTALL)
        if input_match:
            raw_input = input_match.group(1).strip()
            action_input = self._parse_tool_input(raw_input)
        else:
            action_input = {}

        return action, action_input

    def _parse_tool_input(self, raw: str) -> dict:
        """JSON ë˜ëŠ” XML í˜•ì‹ì˜ ë„êµ¬ ì…ë ¥ íŒŒì‹±"""
        # JSON ì‹œë„
        try:
            return json.loads(raw)
        except json.JSONDecodeError:
            pass

        # XML ì‹œë„ (DeepSeekì´ ê°€ë” XMLë¡œ ì‘ë‹µ)
        try:
            return self._parse_xml_input(raw)
        except Exception:
            pass

        # Key=Value í˜•ì‹ ì‹œë„
        return self._parse_kv_input(raw)
```

#### Task 1.3: AgentFactory êµ¬í˜„
- ëª©ì : ëª¨ë¸ ëŠ¥ë ¥ì— ë”°ë¼ ì ì ˆí•œ Agent ì„ íƒ
- íŒŒì¼: `src/agent/agent_factory.py` (ì‹ ê·œ)

```python
class AgentFactory:
    @staticmethod
    def create_agent(llm, tools, prompt) -> ToolCallingAgent | TextReActAgent:
        """ëª¨ë¸ ëŠ¥ë ¥ì— ë”°ë¼ ì ì ˆí•œ Agent ìƒì„±"""
        model_name = getattr(llm, "model", "") or getattr(llm, "model_name", "")
        capability = detect_capability(model_name)

        if capability.preferred_react_format == "tool_calling":
            # ê¸°ì¡´ LangGraph create_react_agent ì‚¬ìš©
            return create_react_agent(model=llm, tools=tools, prompt=prompt)
        else:
            # í…ìŠ¤íŠ¸ ê¸°ë°˜ ReAct Agent ì‚¬ìš©
            return TextReActAgent(llm=llm, tools=tools, prompt=prompt)
```

### 3.4 Phase 2: Output Parser ê°•í™” + StructuredTool (CX ë¬¸ì„œ ë°˜ì˜) â­ ENHANCED

#### Task 2.0: StructuredTool with args_schema (CX ë¬¸ì„œ) â­ NEW
- ëª©ì : ë„êµ¬ ì…ë ¥ ìë™ ê²€ì¦ ë° coercion
- íŒŒì¼: `src/agent/tools/*.py` (ìˆ˜ì •)

```python
# í˜„ì¬: @tool ë°ì½”ë ˆì´í„°ë§Œ ì‚¬ìš© (ìŠ¤í‚¤ë§ˆ ì—†ìŒ)
@tool
def save_generated_question(
    item_type: str,
    stem: str,
    choices: list[str] | None = None,
    ...
) -> dict[str, Any]:
    ...

# ê°œì„ : StructuredTool with Pydantic args_schema
class SaveQuestionArgs(BaseModel):
    """Tool 5 ì…ë ¥ ìŠ¤í‚¤ë§ˆ - LangGraphê°€ ìë™ ê²€ì¦"""
    item_type: Literal["multiple_choice", "true_false", "short_answer"]
    stem: str = Field(min_length=1, max_length=2000)
    choices: list[str] | None = None
    correct_key: str | None = None
    correct_keywords: list[str] | None = None
    difficulty: int = Field(ge=1, le=10, default=5)
    categories: list[str] = Field(default_factory=lambda: ["general"])
    round_id: str
    session_id: str = "unknown"
    validation_score: float | None = None

    @model_validator(mode="after")
    def validate_answer_fields(self):
        if self.item_type == "multiple_choice":
            if not self.correct_key or not self.choices:
                raise ValueError("MC requires correct_key and choices")
        elif self.item_type == "short_answer":
            if not self.correct_keywords:
                raise ValueError("SA requires correct_keywords")
        return self

# StructuredTool ìƒì„±
save_generated_question = StructuredTool.from_function(
    func=_save_generated_question_impl,
    name="save_generated_question",
    description="Save a validated question to the question bank",
    args_schema=SaveQuestionArgs,
)
```

**ì¥ì :**
- LangGraphê°€ ìë™ìœ¼ë¡œ ì…ë ¥ ê²€ì¦
- ì˜ëª»ëœ íƒ€ì… ìë™ coercion (string â†’ int ë“±)
- ëˆ„ë½ëœ í•„ìˆ˜ í•„ë“œ ì¦‰ì‹œ ê°ì§€

#### Task 2.1: ActionSanitizer ì „ì²˜ë¦¬ ë‹¨ê³„ (CX ë¬¸ì„œ) â­ NEW
- ëª©ì : LangGraph ì‹¤í–‰ ì „ XML/YAML â†’ JSON ë³€í™˜
- íŒŒì¼: `src/agent/action_sanitizer.py` (ì‹ ê·œ)

```python
from langchain_core.runnables import RunnableLambda
from langchain_core.messages import AIMessage
import re
import json

class ActionSanitizer:
    """
    LangGraph state machineì— ì‚½ì…ë˜ëŠ” ì „ì²˜ë¦¬ ë‹¨ê³„.
    DeepSeekì˜ XML tool callì„ JSONìœ¼ë¡œ ë³€í™˜.
    """

    XML_PATTERNS = [
        # <tool_call><name>...</name><arguments>...</arguments></tool_call>
        (r"<tool_call>\s*<name>(.+?)</name>\s*<arguments>(.+?)</arguments>\s*</tool_call>",
         lambda m: {"name": m.group(1).strip(), "args": m.group(2).strip()}),

        # <function name="..."><parameter>...</parameter></function>
        (r'<function\s+name="(.+?)"[^>]*>(.+?)</function>',
         lambda m: {"name": m.group(1), "args": m.group(2)}),
    ]

    @classmethod
    def sanitize(cls, state: dict) -> dict:
        """LangGraph stateì—ì„œ ë§ˆì§€ë§‰ AIMessageë¥¼ ê²€ì‚¬í•˜ê³  ì •ê·œí™”"""
        messages = state.get("messages", [])
        if not messages:
            return state

        last_message = messages[-1]
        if not isinstance(last_message, AIMessage):
            return state

        content = last_message.content
        sanitized = False

        for pattern, extractor in cls.XML_PATTERNS:
            matches = list(re.finditer(pattern, content, re.DOTALL))
            if matches:
                # XMLì„ JSON Action Inputìœ¼ë¡œ ë³€í™˜
                for match in matches:
                    tool_info = extractor(match)
                    json_replacement = f"Action: {tool_info['name']}\nAction Input: {tool_info['args']}"
                    content = content.replace(match.group(0), json_replacement)
                sanitized = True

        if sanitized:
            logger.info(f"ActionSanitizer: Converted XML to JSON format")
            # ìƒˆ ë©”ì‹œì§€ë¡œ êµì²´
            messages[-1] = AIMessage(content=content)
            return {**state, "messages": messages}

        return state

# LangGraphì— ì‚½ì…
def create_sanitized_react_agent(llm, tools, prompt):
    """ActionSanitizerê°€ í¬í•¨ëœ ReAct Agent"""
    base_agent = create_react_agent(llm, tools, prompt)

    # ì—ì´ì „íŠ¸ ë…¸ë“œ ì•ì— sanitizer ì‚½ì…
    return base_agent.pipe(RunnableLambda(ActionSanitizer.sanitize))
```

#### Task 2.2: parse_json_robust() ì „ì—­ í™œìš© (CX ë¬¸ì„œ) â­ ENHANCED
- ëª©ì : ê¸°ì¡´ robust íŒŒì„œê°€ ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” ê³³ì— ì ìš©
- íŒŒì¼: `src/agent/tools/score_and_explain_tool.py` (ìˆ˜ì •)

```python
# í˜„ì¬: ë‹¨ìˆœ json.loads ì‚¬ìš© (src/agent/tools/score_and_explain_tool.py:231)
try:
    result = json.loads(response_text)  # âŒ ì‹¤íŒ¨ ê°€ëŠ¥
except json.JSONDecodeError as e:
    logger.warning(f"Could not parse...")
    return DEFAULT_LLM_SCORE, "Unable to parse"

# ê°œì„ : parse_json_robust ë˜ëŠ” AgentOutputConverter ì‚¬ìš©
from src.agent.llm_agent import parse_json_robust
# ë˜ëŠ”
from src.agent.output_converter import AgentOutputConverter

try:
    result = parse_json_robust(response_text)  # âœ… 5ê°€ì§€ cleanup ì „ëµ
except json.JSONDecodeError:
    # ì—¬ì „íˆ ì‹¤íŒ¨í•˜ë©´ ê¸°ë³¸ê°’
    return DEFAULT_LLM_SCORE, "Unable to parse after robust attempts"
```

**ì ìš© ëŒ€ìƒ íŒŒì¼:**
- `src/agent/tools/score_and_explain_tool.py:231` (_call_llm_score_short_answer)
- `src/agent/tools/score_and_explain_tool.py:391` (_generate_explanation)
- `src/agent/llm_agent.py:1253` (_parse_agent_output_score)

#### Task 2.3: MultiFormatOutputParser êµ¬í˜„
- ëª©ì : JSON, XML, Key-Value ë“± ë‹¤ì–‘í•œ ì¶œë ¥ í˜•ì‹ ì²˜ë¦¬
- íŒŒì¼: `src/agent/output_parser.py` (ì‹ ê·œ)

```python
class MultiFormatOutputParser:
    """ë‹¤ì–‘í•œ LLM ì¶œë ¥ í˜•ì‹ì„ ì •ê·œí™”ëœ í˜•íƒœë¡œ ë³€í™˜"""

    @staticmethod
    def parse_tool_call(content: str) -> list[ToolCall]:
        """
        ì§€ì›í•˜ëŠ” í˜•ì‹:
        1. JSON: {"tool": "name", "args": {...}}
        2. XML: <tool name="..."><arg>...</arg></tool>
        3. Text: Action: name\nAction Input: {...}
        4. Function Call: tool_name(arg1, arg2)
        """
        parsers = [
            JSONToolCallParser,
            XMLToolCallParser,
            TextReActParser,
            FunctionCallParser,
        ]

        for parser in parsers:
            try:
                result = parser.parse(content)
                if result:
                    return result
            except Exception:
                continue

        return []

class XMLToolCallParser:
    """DeepSeekì´ ì¶œë ¥í•˜ëŠ” XML í˜•ì‹ íŒŒì‹±"""

    @staticmethod
    def parse(content: str) -> list[ToolCall] | None:
        # <tool_call> ë˜ëŠ” <function_call> íƒœê·¸ ì°¾ê¸°
        patterns = [
            r"<tool_call>\s*<name>(.+?)</name>\s*<arguments>(.+?)</arguments>\s*</tool_call>",
            r"<function_call>\s*<name>(.+?)</name>\s*<parameters>(.+?)</parameters>\s*</function_call>",
        ]

        for pattern in patterns:
            matches = re.findall(pattern, content, re.DOTALL)
            if matches:
                return [
                    ToolCall(name=name.strip(), args=XMLToolCallParser._parse_args(args))
                    for name, args in matches
                ]
        return None
```

#### Task 2.2: FinalAnswerExtractor ê°•í™”
- ëª©ì : ë‹¤ì–‘í•œ Final Answer í˜•ì‹ ì²˜ë¦¬
- íŒŒì¼: `src/agent/output_converter.py` (ìˆ˜ì •)

```python
# ì¶”ê°€í•  ë©”ì„œë“œ
@staticmethod
def extract_final_answer(content: str) -> dict | list | None:
    """
    ë‹¤ì–‘í•œ Final Answer í˜•ì‹ ì§€ì›:
    1. Final Answer: [JSON]
    2. Final Answer:\n```json\n[JSON]\n```
    3. <final_answer>[JSON]</final_answer>
    4. **Final Answer**: [JSON]
    """
    patterns = [
        r"Final Answer:\s*```json\s*(.+?)\s*```",
        r"Final Answer:\s*(.+?)(?:\n\nThought:|$)",
        r"<final_answer>\s*(.+?)\s*</final_answer>",
        r"\*\*Final Answer\*\*:\s*(.+?)(?:\n\n|$)",
    ]

    for pattern in patterns:
        match = re.search(pattern, content, re.DOTALL)
        if match:
            json_str = match.group(1).strip()
            try:
                return json.loads(json_str)
            except json.JSONDecodeError:
                continue

    return None
```

### 3.4 Phase 3: Provider ì „ëµ ê°œì„  (Medium Risk)

#### Task 3.1: DeepSeekProvider ì „ìš© êµ¬í˜„
- ëª©ì : DeepSeek ëª¨ë¸ì˜ íŠ¹ì„±ì— ë§ëŠ” ì„¤ì •
- íŒŒì¼: `src/agent/config.py` (ìˆ˜ì •)

```python
class DeepSeekProvider(LLMProvider):
    """
    DeepSeek ì „ìš© Provider.

    ì£¼ìš” ì„¤ì •:
    - Tool Calling ë¹„í™œì„±í™” (ë¶ˆì•ˆì •)
    - JSON mode ì‚¬ìš© (json_schema ëŒ€ì‹ )
    - ë‚®ì€ temperature (í˜•ì‹ ì¼ê´€ì„±)
    """

    def create(self) -> ChatOpenAI:
        base_url = getenv("DEEPSEEK_BASE_URL") or getenv("LITELLM_BASE_URL")
        api_key = getenv("DEEPSEEK_API_KEY") or getenv("LITELLM_API_KEY", "sk-dummy")

        return ChatOpenAI(
            model="deepseek-chat",  # deepseek-v3
            api_key=api_key,
            base_url=base_url,
            temperature=0.1,  # ë” ë‚®ì€ temperatureë¡œ í˜•ì‹ ì¼ê´€ì„± í–¥ìƒ
            max_tokens=8192,
            timeout=60,  # ë” ê¸´ íƒ€ì„ì•„ì›ƒ
            # Tool Callingì€ TextReActAgentì—ì„œ ìˆ˜ë™ ì²˜ë¦¬
        )

class LLMFactory:
    @staticmethod
    def get_provider() -> LLMProvider:
        model = getenv("LLM_MODEL", "").lower()

        if "deepseek" in model:
            return DeepSeekProvider()
        elif getenv("USE_LITE_LLM", "False").lower() == "true":
            return LiteLLMProvider()
        else:
            return GoogleGenerativeAIProvider()
```

#### Task 3.2: í”„ë¡¬í”„íŠ¸ ê°•í™” (DeepSeek ìµœì í™”)
- ëª©ì : DeepSeekì´ ë” ì˜ ë”°ë¥´ëŠ” í”„ë¡¬í”„íŠ¸ í˜•ì‹
- íŒŒì¼: `src/agent/prompts/prompt_content.py` (ìˆ˜ì •)

```python
# DeepSeek ì „ìš© ê°•í™” ì§€ì‹œë¬¸ ì¶”ê°€
DEEPSEEK_FORMAT_ENFORCEMENT = """
=== CRITICAL OUTPUT FORMAT REQUIREMENTS ===

You MUST follow this EXACT format. No exceptions.

DO NOT use XML tags like <tool_call> or <function>.
DO NOT use markdown code blocks for tool calls.
ALWAYS use this plain text format:

```
Thought: [your reasoning here]
Action: [exact tool name from the list above]
Action Input: {"param1": "value1", "param2": "value2"}
```

WRONG (DO NOT DO THIS):
âŒ <tool_call><name>get_user_profile</name>...</tool_call>
âŒ ```json
   {"tool": "get_user_profile", ...}
   ```
âŒ get_user_profile(user_id="...")

CORRECT (DO THIS):
âœ“ Thought: I need to get user profile information
âœ“ Action: get_user_profile
âœ“ Action Input: {"user_id": "e79a0ee1-2a36-4383-91c5-9a8a01f27b62"}
"""
```

### 3.6 Phase 4: í†µí•© í…ŒìŠ¤íŠ¸ ë° ê²€ì¦ (CX ë¬¸ì„œ ë°˜ì˜) â­ ENHANCED

> **CX ë¬¸ì„œ ì§€ì **: `src/agent/tests` ë””ë ‰í† ë¦¬ê°€ ë¹„ì–´ìˆìŒ - í…ŒìŠ¤íŠ¸ í•„ìˆ˜

#### Task 4.0: í…ŒìŠ¤íŠ¸ ì¸í”„ë¼ êµ¬ì¶• (CX ë¬¸ì„œ) â­ NEW
- ëª©ì : `src/agent/tests/` ë””ë ‰í† ë¦¬ì— í…ŒìŠ¤íŠ¸ ê¸°ë°˜ êµ¬ì¶•
- íŒŒì¼: `tests/agent/` (ì‹ ê·œ ë””ë ‰í† ë¦¬)

```
tests/agent/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ conftest.py                      # ê³µí†µ fixtures
â”œâ”€â”€ fixtures/
â”‚   â”œâ”€â”€ mock_llm_responses.py        # ë‹¤ì–‘í•œ LLM ì‘ë‹µ mocks
â”‚   â”œâ”€â”€ xml_tool_calls.py            # DeepSeek XML í˜•ì‹ ìƒ˜í”Œ
â”‚   â””â”€â”€ json_tool_calls.py           # Gemini JSON í˜•ì‹ ìƒ˜í”Œ
â”œâ”€â”€ test_model_capability.py         # ModelCapabilityProfile í…ŒìŠ¤íŠ¸
â”œâ”€â”€ test_action_sanitizer.py         # XML â†’ JSON ë³€í™˜ í…ŒìŠ¤íŠ¸
â”œâ”€â”€ test_structured_tools.py         # StructuredTool ê²€ì¦ í…ŒìŠ¤íŠ¸
â”œâ”€â”€ test_text_react_agent.py         # TextReActAgent í…ŒìŠ¤íŠ¸
â”œâ”€â”€ test_output_parser.py            # MultiFormatOutputParser í…ŒìŠ¤íŠ¸
â””â”€â”€ test_multi_model_compatibility.py # í†µí•© í…ŒìŠ¤íŠ¸
```

```python
# tests/agent/conftest.py
import pytest
from unittest.mock import MagicMock, AsyncMock
from langchain_core.messages import AIMessage, HumanMessage, ToolMessage

@pytest.fixture
def mock_gemini_response():
    """Gemini ìŠ¤íƒ€ì¼ JSON tool call ì‘ë‹µ"""
    return AIMessage(
        content="",
        tool_calls=[{
            "name": "get_user_profile",
            "args": {"user_id": "test-123"},
            "id": "call_abc123"
        }]
    )

@pytest.fixture
def mock_deepseek_xml_response():
    """DeepSeek ìŠ¤íƒ€ì¼ XML ì‘ë‹µ - ì‹¤ì œ ì‚¬ë‚´ ë¡œê·¸ì—ì„œ ì¶”ì¶œ"""
    return AIMessage(
        content='''Thought: I need to get user profile
<tool_call>
<name>get_user_profile</name>
<arguments>{"user_id": "test-123"}</arguments>
</tool_call>'''
    )

@pytest.fixture
def mock_deepseek_malformed_response():
    """DeepSeek ìŠ¤íƒ€ì¼ ì˜ëª»ëœ í˜•ì‹"""
    return AIMessage(
        content='''Thought: Getting profile
Action: get_user_profile
Action Input: user_id="test-123"  # JSON ì•„ë‹Œ key=value
'''
    )
```

#### Task 4.1: Multi-Model í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸
- ëª©ì : ë‹¤ì–‘í•œ ëª¨ë¸ì—ì„œ ë™ì‘ ê²€ì¦
- íŒŒì¼: `tests/agent/test_multi_model_compatibility.py` (ì‹ ê·œ)

```python
import pytest
from src.agent.agent_factory import AgentFactory
from src.agent.model_capability import detect_capability

@pytest.mark.parametrize("model_name,expected_format", [
    ("gemini-2.0-flash", "tool_calling"),
    ("deepseek-v3", "text"),
    ("deepseek-chat", "text"),
    ("gpt-4", "tool_calling"),
    ("claude-3", "tool_calling"),
])
def test_capability_detection(model_name, expected_format):
    capability = detect_capability(model_name)
    assert capability.preferred_react_format == expected_format

@pytest.mark.asyncio
async def test_text_react_agent_basic():
    """TextReActAgentê°€ í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ëŠ”ì§€ í™•ì¸"""
    # Mock LLM that returns text-based ReAct
    mock_llm = MockLLM(responses=[
        "Thought: I need to get user profile\nAction: get_user_profile\nAction Input: {\"user_id\": \"test-123\"}",
        "Thought: Got the profile, now I can answer\nFinal Answer: {\"status\": \"success\"}"
    ])

    agent = TextReActAgent(llm=mock_llm, tools=MOCK_TOOLS, prompt=TEST_PROMPT)
    result = await agent.ainvoke([HumanMessage(content="Get user profile")])

    assert "Final Answer" in result["messages"][-1].content
```

#### Task 4.2: Output Parser í…ŒìŠ¤íŠ¸
- ëª©ì : ë‹¤ì–‘í•œ ì¶œë ¥ í˜•ì‹ íŒŒì‹± ê²€ì¦
- íŒŒì¼: `tests/agent/test_output_parser.py` (ì‹ ê·œ)

```python
class TestMultiFormatOutputParser:
    def test_parse_json_tool_call(self):
        content = 'Action Input: {"user_id": "123"}'
        result = MultiFormatOutputParser.parse_tool_call(content)
        assert result[0].args == {"user_id": "123"}

    def test_parse_xml_tool_call(self):
        content = '<tool_call><name>get_user_profile</name><arguments>{"user_id": "123"}</arguments></tool_call>'
        result = MultiFormatOutputParser.parse_tool_call(content)
        assert result[0].name == "get_user_profile"

    def test_parse_text_react(self):
        content = "Thought: ...\nAction: save_question\nAction Input: {\"stem\": \"What is AI?\"}"
        result = MultiFormatOutputParser.parse_tool_call(content)
        assert result[0].name == "save_question"
```

#### Task 4.3: êµ¬ì¡°í™”ëœ ë¡œê¹… (CX ë¬¸ì„œ) â­ NEW
- ëª©ì : ì‚¬ë‚´/ì‚¬ì™¸ í™˜ê²½ ê°„ ë””ë²„ê¹… ìš©ì´ì„± í–¥ìƒ
- íŒŒì¼: `src/agent/structured_logging.py` (ì‹ ê·œ)

```python
import json
import logging
from dataclasses import dataclass, asdict
from datetime import datetime
from typing import Any

@dataclass
class AgentExecutionLog:
    """êµ¬ì¡°í™”ëœ Agent ì‹¤í–‰ ë¡œê·¸"""
    timestamp: str
    model_name: str
    capability_profile: dict
    iteration: int
    step_type: str  # "tool_call" | "observation" | "final_answer"

    # ì›ë³¸ vs ì •ê·œí™”ëœ ë°ì´í„°
    raw_content: str
    sanitized_content: str | None
    sanitization_applied: bool

    # ë„êµ¬ í˜¸ì¶œ ì •ë³´
    tool_name: str | None
    tool_args: dict | None
    tool_result: Any | None

    # ì—ëŸ¬ ì •ë³´
    error: str | None = None

class StructuredAgentLogger:
    """ì‚¬ë‚´/ì‚¬ì™¸ í™˜ê²½ ëª¨ë‘ì—ì„œ ì¼ê´€ëœ JSON ë¡œê·¸ ì¶œë ¥"""

    def __init__(self, model_name: str, capability_profile: dict):
        self.model_name = model_name
        self.capability_profile = capability_profile
        self.iteration = 0
        self.logs: list[AgentExecutionLog] = []

    def log_tool_call(
        self,
        raw_content: str,
        sanitized_content: str | None,
        tool_name: str,
        tool_args: dict
    ):
        """ë„êµ¬ í˜¸ì¶œ ë¡œê·¸"""
        log = AgentExecutionLog(
            timestamp=datetime.now().isoformat(),
            model_name=self.model_name,
            capability_profile=self.capability_profile,
            iteration=self.iteration,
            step_type="tool_call",
            raw_content=raw_content[:500],  # ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ëƒ„
            sanitized_content=sanitized_content[:500] if sanitized_content else None,
            sanitization_applied=sanitized_content is not None,
            tool_name=tool_name,
            tool_args=tool_args,
            tool_result=None,
        )
        self._emit(log)

    def log_observation(self, tool_name: str, result: Any):
        """ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ ë¡œê·¸"""
        log = AgentExecutionLog(
            timestamp=datetime.now().isoformat(),
            model_name=self.model_name,
            capability_profile=self.capability_profile,
            iteration=self.iteration,
            step_type="observation",
            raw_content="",
            sanitized_content=None,
            sanitization_applied=False,
            tool_name=tool_name,
            tool_args=None,
            tool_result=result,
        )
        self._emit(log)
        self.iteration += 1

    def _emit(self, log: AgentExecutionLog):
        """JSON í˜•ì‹ìœ¼ë¡œ ë¡œê·¸ ì¶œë ¥ - íŒŒì¼ ë˜ëŠ” stdout"""
        self.logs.append(log)
        # êµ¬ì¡°í™”ëœ JSON ë¡œê·¸ ì¶œë ¥
        logging.info(f"AGENT_LOG: {json.dumps(asdict(log), ensure_ascii=False)}")

    def export_session(self) -> str:
        """ì „ì²´ ì„¸ì…˜ ë¡œê·¸ë¥¼ JSON íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸° (ë””ë²„ê¹…ìš©)"""
        return json.dumps([asdict(log) for log in self.logs], indent=2, ensure_ascii=False)
```

**ì‚¬ìš© ì˜ˆ:**
```python
# ItemGenAgentì—ì„œ ì‚¬ìš©
class ItemGenAgent:
    def __init__(self, ...):
        self.logger = StructuredAgentLogger(
            model_name=self.llm.model,
            capability_profile=asdict(self.capability)
        )

    async def _execute_tool(self, raw_content: str, tool_call: ToolCall):
        # ë¡œê·¸ ê¸°ë¡
        self.logger.log_tool_call(
            raw_content=raw_content,
            sanitized_content=sanitized if was_sanitized else None,
            tool_name=tool_call.name,
            tool_args=tool_call.args
        )

        result = self.tools[tool_call.name].invoke(tool_call.args)

        self.logger.log_observation(tool_call.name, result)
```

**ì¥ì :**
- ì‚¬ë‚´ DeepSeek ì‹¤í–‰ ë¡œê·¸ë¥¼ JSON íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸° ê°€ëŠ¥
- ì‚¬ì™¸ì—ì„œ ë™ì¼ í˜•ì‹ìœ¼ë¡œ ë¡œë“œí•˜ì—¬ ë¹„êµ ë¶„ì„
- grep/jqë¡œ ì‰½ê²Œ í•„í„°ë§ ê°€ëŠ¥

---

## 4. êµ¬í˜„ ìš°ì„ ìˆœìœ„ ë° ì¼ì •

### 4.1 ìš°ì„ ìˆœìœ„ ë§¤íŠ¸ë¦­ìŠ¤ (Updated with G, CX feedback)

| Phase | Task | ì˜í–¥ë„ | ìœ„í—˜ë„ | ìš°ì„ ìˆœìœ„ | ì¶œì²˜ |
|-------|------|--------|--------|----------|------|
| **0** | with_structured_output ë„ì… | **Critical** | Medium | **P0** | G ë¬¸ì„œ |
| **0** | Two-Step Gather-Generate | **Critical** | Medium | **P0** | G ë¬¸ì„œ |
| **0** | Pydantic ì‘ë‹µ ëª¨ë¸ ê°•í™” | High | Low | P0 | G ë¬¸ì„œ |
| 1 | ModelCapabilityProfile | High | Low | P0 | A+CX |
| 1 | TextReActAgent | High | Medium | P1 | A |
| 1 | AgentFactory | High | Low | P1 | A |
| **2** | StructuredTool args_schema | **High** | Low | **P0** | CX ë¬¸ì„œ |
| **2** | ActionSanitizer | **High** | Medium | **P0** | CX ë¬¸ì„œ |
| **2** | parse_json_robust ì „ì—­ í™œìš© | High | Low | P1 | CX ë¬¸ì„œ |
| 2 | MultiFormatOutputParser | High | Medium | P1 | A |
| 3 | DeepSeekProvider | Medium | Low | P2 | A |
| 3 | í”„ë¡¬í”„íŠ¸ ë‹¨ìˆœí™” | Medium | Low | P2 | G ë¬¸ì„œ |
| **4** | í…ŒìŠ¤íŠ¸ ì¸í”„ë¼ êµ¬ì¶• | **High** | Low | **P0** | CX ë¬¸ì„œ |
| 4 | Multi-Model í…ŒìŠ¤íŠ¸ | High | Low | P1 | A |
| **4** | êµ¬ì¡°í™”ëœ ë¡œê¹… | **High** | Low | **P1** | CX ë¬¸ì„œ |

### 4.2 ì „ëµì  ì ‘ê·¼ ë°©ì‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Option A: "ê·¼ë³¸ì  í•´ê²°" (G ë¬¸ì„œ ê¶Œì¥)                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”‚
â”‚  Phase 0 ì§‘ì¤‘ â†’ with_structured_outputìœ¼ë¡œ íŒŒì‹± ë¬¸ì œ ì œê±°    â”‚
â”‚  ì¥ì : ê¹”ë”í•œ í•´ê²°, ìœ ì§€ë³´ìˆ˜ ìš©ì´                             â”‚
â”‚  ë‹¨ì : í° ë¦¬íŒ©í† ë§ í•„ìš”, ê¸°ì¡´ ReAct ë¡œì§ ëŒ€í­ ìˆ˜ì •            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           vs
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Option B: "ì ì§„ì  ê°œì„ " (A ë¬¸ì„œ + CX ë¬¸ì„œ ì¡°í•©)              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”‚
â”‚  Phase 1-2 ì§‘ì¤‘ â†’ ê¸°ì¡´ êµ¬ì¡° ìœ ì§€í•˜ë©´ì„œ í˜¸í™˜ì„± ë ˆì´ì–´ ì¶”ê°€     â”‚
â”‚  ì¥ì : ë‚®ì€ ìœ„í—˜, ë‹¨ê³„ì  ê²€ì¦ ê°€ëŠ¥                            â”‚
â”‚  ë‹¨ì : ë³µì¡ë„ ì¦ê°€, ì„ì‹œë°©í¸ ëŠë‚Œ                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ê¶Œì¥: Option A + í•„ìˆ˜ B ìš”ì†Œ ì¡°í•©**
- Phase 0 (G ë¬¸ì„œ)ì˜ `with_structured_output`ì„ ë¨¼ì € ì‹œë„
- ì‹¤íŒ¨ ì‹œ Phase 2 (CX ë¬¸ì„œ)ì˜ `ActionSanitizer`ë¡œ fallback
- í…ŒìŠ¤íŠ¸/ë¡œê¹…ì€ ì–´ëŠ ì˜µì…˜ì´ë“  í•„ìˆ˜

### 4.3 êµ¬í˜„ ìˆœì„œ (Updated)

```
Week 1: Phase 0 + í…ŒìŠ¤íŠ¸ ì¸í”„ë¼ (í•µì‹¬)
â”œâ”€â”€ Day 1: í…ŒìŠ¤íŠ¸ ì¸í”„ë¼ êµ¬ì¶• (tests/agent/)
â”œâ”€â”€ Day 2: ModelCapabilityProfile êµ¬í˜„ + í…ŒìŠ¤íŠ¸
â”œâ”€â”€ Day 3-4: with_structured_output ë„ì… (llm_agent.py)
â””â”€â”€ Day 5: Two-Step ì•„í‚¤í…ì²˜ í”„ë¡œí† íƒ€ì…

Week 2: Phase 2 (í˜¸í™˜ì„± ë ˆì´ì–´)
â”œâ”€â”€ Day 1: StructuredTool args_schema ë§ˆì´ê·¸ë ˆì´ì…˜
â”œâ”€â”€ Day 2-3: ActionSanitizer êµ¬í˜„ + í…ŒìŠ¤íŠ¸
â”œâ”€â”€ Day 4: parse_json_robust ì „ì—­ ì ìš©
â””â”€â”€ Day 5: êµ¬ì¡°í™”ëœ ë¡œê¹… êµ¬í˜„

Week 3: Phase 1 + ê²€ì¦
â”œâ”€â”€ Day 1-2: TextReActAgent (fallbackìš©)
â”œâ”€â”€ Day 3: AgentFactory í†µí•©
â”œâ”€â”€ Day 4: Multi-Model í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸
â””â”€â”€ Day 5: ì‚¬ë‚´ í™˜ê²½ ê²€ì¦ + ë¬¸ì„œí™”
```

---

## 5. ìœ„í—˜ ìš”ì†Œ ë° ì™„í™” ë°©ì•ˆ

### 5.1 ê¸°ìˆ ì  ìœ„í—˜

| ìœ„í—˜ | ì˜í–¥ | í™•ë¥  | ì™„í™” ë°©ì•ˆ |
|------|------|------|-----------|
| TextReActAgent ë£¨í”„ ë¬´í•œë°˜ë³µ | High | Medium | max_iterations + timeout ì„¤ì • |
| XML íŒŒì‹± ì‹¤íŒ¨ | Medium | Medium | ì—¬ëŸ¬ íŒŒì„œ fallback chain |
| DeepSeek API ë¶ˆì•ˆì • | High | Medium | ì¬ì‹œë„ ë¡œì§ + í´ë°± |
| í”„ë¡¬í”„íŠ¸ ë³€ê²½ìœ¼ë¡œ Gemini ì˜í–¥ | High | Low | ëª¨ë¸ë³„ í”„ë¡¬í”„íŠ¸ ë¶„ë¦¬ |

### 5.2 ì™„í™” ì½”ë“œ ì˜ˆì‹œ

```python
# ë¬´í•œ ë£¨í”„ ë°©ì§€
class TextReActAgent:
    MAX_ITERATIONS = 10
    ITERATION_TIMEOUT = 120  # seconds

    async def ainvoke(self, messages):
        start_time = time.time()

        for i in range(self.MAX_ITERATIONS):
            if time.time() - start_time > self.ITERATION_TIMEOUT:
                logger.warning("Iteration timeout reached")
                break

            # ... ì‹¤í–‰ ë¡œì§ ...

        return self._create_error_response("Max iterations reached")
```

---

## 6. ì°¸ê³  ìë£Œ

### 6.1 LangChain/LangGraph ê³µì‹ ë¬¸ì„œ
- [ReAct Agent Structured Output](https://langchain-ai.github.io/langgraph/how-tos/react-agent-structured-output/)
- [ReAct Agent from Scratch](https://langchain-ai.github.io/langgraph/how-tos/react-agent-from-scratch/)
- [LangChain + LangGraph 1.0](https://blog.langchain.com/langchain-langgraph-1dot0/)

### 6.2 DeepSeek í˜¸í™˜ì„± ì´ìŠˆ
- [DeepSeek V3 Structured Output Issue #29282](https://github.com/langchain-ai/langchain/issues/29282)
- [LiteLLM DeepSeek JSON Issue #7580](https://github.com/BerriAI/litellm/issues/7580)
- [LiteLLM DeepSeek Docs](https://docs.litellm.ai/docs/providers/deepseek)

### 6.3 í”„ë¡œì íŠ¸ ë‚´ë¶€ ë¬¸ì„œ
- `docs/postmortem-prompt-escaping-solid-refactoring.md`
- `docs/PROMPT_SOLID_REFACTORING.md`
- `docs/TOOL_DEFINITIONS_SUMMARY.md`

---

## 7. ê²°ë¡ 

### 7.1 í•µì‹¬ ê°œì„ ì  ìš”ì•½ (Updated with G, CX feedback)

| ì¹´í…Œê³ ë¦¬ | ê°œì„ ì  | ì¶œì²˜ |
|----------|--------|------|
| **ê·¼ë³¸ì  í•´ê²°** | `with_structured_output`ìœ¼ë¡œ ìˆ˜ë™ íŒŒì‹± ì œê±° | G ë¬¸ì„œ |
| **ì•„í‚¤í…ì²˜** | Two-Step "Gather-Then-Generate" ë‹¨ìˆœí™” | G ë¬¸ì„œ |
| **í˜¸í™˜ì„±** | `ActionSanitizer`ë¡œ XML â†’ JSON ì „ì²˜ë¦¬ | CX ë¬¸ì„œ |
| **íƒ€ì… ì•ˆì „ì„±** | `StructuredTool` with `args_schema` | CX ë¬¸ì„œ |
| **íŒŒì‹± ê°•í™”** | `parse_json_robust` ì „ì—­ í™œìš© | CX ë¬¸ì„œ |
| **í…ŒìŠ¤íŠ¸** | `tests/agent/` í…ŒìŠ¤íŠ¸ ì¸í”„ë¼ êµ¬ì¶• | CX ë¬¸ì„œ |
| **ë””ë²„ê¹…** | êµ¬ì¡°í™”ëœ JSON ë¡œê¹… | CX ë¬¸ì„œ |
| **Fallback** | `TextReActAgent` (Tool Calling ë¯¸ì§€ì› ì‹œ) | A ë¬¸ì„œ |
| **í”„ë¡œíŒŒì¼** | `ModelCapabilityProfile` ëª¨ë¸ë³„ ëŠ¥ë ¥ ê°ì§€ | A+CX |

### 7.2 ê¸°ëŒ€ íš¨ê³¼

```
Before (í˜„ì¬):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Gemini:    âœ… ì •ìƒ (native tool calling)    â”‚
â”‚ DeepSeek:  âŒ ì‹¤íŒ¨ (XML ì¶œë ¥, íŒŒì‹± ì—ëŸ¬)     â”‚
â”‚ GPT-4:     âš ï¸ ë¯¸í…ŒìŠ¤íŠ¸                       â”‚
â”‚ Claude:    âš ï¸ ë¯¸í…ŒìŠ¤íŠ¸                       â”‚
â”‚ ë””ë²„ê¹…:    ğŸ˜° ìˆ˜ë™ ë¡œê·¸ ë³µì‚¬ í•„ìš”             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

After (ê°œì„  í›„):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Gemini:    âœ… ì •ìƒ (with_structured_output) â”‚
â”‚ DeepSeek:  âœ… ì •ìƒ (Sanitizer + TextReAct)  â”‚
â”‚ GPT-4:     âœ… ì •ìƒ (with_structured_output) â”‚
â”‚ Claude:    âœ… ì •ìƒ (with_structured_output) â”‚
â”‚ ê¸°íƒ€:      âš ï¸ TextReActAgent fallback       â”‚
â”‚ ë””ë²„ê¹…:    ğŸ˜Š JSON ë¡œê·¸ ìë™ ë‚´ë³´ë‚´ê¸°        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7.3 ë‹¤ìŒ ë‹¨ê³„

1. **íŒ€ ë…¼ì˜**: Option A (ê·¼ë³¸ì  í•´ê²°) vs Option B (ì ì§„ì  ê°œì„ ) ì„ íƒ
2. **Phase 0 PoC**: `with_structured_output` ë¨¼ì € ì‚¬ë‚´ DeepSeekì—ì„œ í…ŒìŠ¤íŠ¸
   - ì„±ê³µ ì‹œ: Phase 0 ì¤‘ì‹¬ìœ¼ë¡œ ì§„í–‰
   - ì‹¤íŒ¨ ì‹œ: Phase 1-2 ì¤‘ì‹¬ìœ¼ë¡œ ì§„í–‰ (ActionSanitizer ë“±)
3. **í…ŒìŠ¤íŠ¸ ì¸í”„ë¼**: ì–´ëŠ ì˜µì…˜ì´ë“  `tests/agent/` ë¨¼ì € êµ¬ì¶•
4. **êµ¬ì¡°í™”ëœ ë¡œê¹…**: ì‚¬ë‚´/ì‚¬ì™¸ ë””ë²„ê¹… ìš©ì´ì„±ì„ ìœ„í•´ ì¡°ê¸° ì ìš©

### 7.4 í”¼ë“œë°± ë°˜ì˜ ì™„ë£Œ

- [x] G ë¬¸ì„œ: `with_structured_output` í™œìš© â†’ Phase 0 ì¶”ê°€
- [x] G ë¬¸ì„œ: Two-Step ì•„í‚¤í…ì²˜ â†’ Task 0.2 ì¶”ê°€
- [x] G ë¬¸ì„œ: í”„ë¡¬í”„íŠ¸ ë‹¨ìˆœí™” â†’ Phase 3.2 ì–¸ê¸‰
- [x] CX ë¬¸ì„œ: `StructuredTool` args_schema â†’ Task 2.0 ì¶”ê°€
- [x] CX ë¬¸ì„œ: `ActionSanitizer` â†’ Task 2.1 ì¶”ê°€
- [x] CX ë¬¸ì„œ: `parse_json_robust` ì „ì—­ í™œìš© â†’ Task 2.2 ì¶”ê°€
- [x] CX ë¬¸ì„œ: í…ŒìŠ¤íŠ¸ ë¶€ì¬ â†’ Task 4.0 ì¶”ê°€
- [x] CX ë¬¸ì„œ: êµ¬ì¡°í™”ëœ ë¡œê¹… â†’ Task 4.3 ì¶”ê°€

---

*ë¬¸ì„œ ì‘ì„±: 2025-12-05*
*ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: 2025-12-05 (v1.1 - G, CX í”¼ë“œë°± ë°˜ì˜)*
